{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4X9M25jzxef"
      },
      "source": [
        "# | 실습3 | MobileNetV2 변형해 보기\n",
        "\n",
        "- **채점 기준**\n",
        "  - 아래 과제 설명을 따라야한다.\n",
        "  - test accuracy가 **80% 이상** 나와야 한다.\n",
        "- **제출**\n",
        "  - output 지우지 말아 주세요"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbiOlVdNzxei",
        "scrolled": false
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlwfSBH3zxej"
      },
      "source": [
        "`BatchNormalization(axis, momentum, epsilon)` : https://keras.io/api/layers/normalization_layers/batch_normalization/\n",
        "- axis: Batch normalization이 적용될 axis. 우리는 채널에 대해서 BN을 적용할 것이다. \n",
        "- momentum: Moving average에 적용될 momentum 계수\n",
        "- epsilon: 0으로 나누는 것을 방지하기 위한 작은 수.\n",
        "\n",
        "\n",
        "`DepthwiseConv2D(kernel_size, strides, padding, use_bias, depthwise_regularizer)` : https://keras.io/api/layers/convolution_layers/depthwise_convolution2d/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbeM7t9Wzxek"
      },
      "source": [
        "paper:[MobileNetV3](https://openaccess.thecvf.com/content_ICCV_2019/papers/Howard_Searching_for_MobileNetV3_ICCV_2019_paper.pdf)  \n",
        "\n",
        "이번 실습에서는 MobileNetV3에서 추가된 내용 중 일부를 반영해 볼 것이다. MobilenetV3에서는 모델의 마지막 부분에 아래 그림과 같은 변화가 있었는데, 요약하자면\n",
        "* Average pooling 앞의 1x1 Convolution layer와 Average pooling layer의 순서를 바꾸어 줌으로써 Computation은 줄이면서 정보의 손실은 최소화하였다.\n",
        "* 위 변화가 일어나게 됨으로써 그 이전 Inverted residual layer에서 projection/filtering을 해 줄 필요가 없어졌다. 따라서 마지막 Inverted residual layer의 Expansion 이후 바로 Average pooling이 오게 된다.\n",
        "* 아래 그림을 보면 더 이해가 쉬울 것이다.\n",
        "<img src=\"https://user-images.githubusercontent.com/37704174/112775642-734f8a80-9078-11eb-9bc1-a860a1fea407.PNG\" width=\"700\" height=\"700\"/> \n",
        "* 마지막 Inverted residual layer는 Original last stage 그림에서 맨 앞 세개이다.\n",
        "\n",
        "\n",
        "<br>\n",
        "위 내용을 참조하여 Network의 마지막 부분을 변형한 MobileNetV2plus를 구성하라. 위 그림상의 H-swish는 고려하지 않아도 된다.\n",
        "<img src=\"https://user-images.githubusercontent.com/37704174/112777027-1229b600-907c-11eb-9f89-a7b61c0843be.PNG\" width=\"700\" height=\"700\"/>  \n",
        "\n",
        "- **채점기준**\n",
        "  - 위의 변경 사항 반영하기\n",
        "    - MobileNetV2에서 마지막 inverted residual block 및 뒷부분을 고치면 됨\n",
        "    - Average pooling의 output의 가로 세로는 1임\n",
        "  - test accuracy **80%** 이상\n",
        "    - BatchNormalization, Activation, Dropout, Regularization, Weight initialization 등 자유롭게 수정, 추가, 제거 가능\n",
        "    - `strides` 수정 가능\n",
        "    - 나머지는 그대로\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zQAEuO1zxek"
      },
      "source": [
        "## Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PwJ-gqa8zxel",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "### Q1. Import modules ###\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Add, ReLU, Input, Dense, Activation, Flatten, Conv2D, \\\n",
        "    DepthwiseConv2D, BatchNormalization, GlobalAveragePooling2D, Dropout, AveragePooling2D\n",
        "from tensorflow.keras.regularizers import l2\n",
        "#########################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LT2NLnjXiM-",
        "outputId": "97267b4b-f489-404d-87e0-b3234ba608a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num_GPUs:1, List:[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Make sure your runtime type is GPU!\n",
        "\"\"\"\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "print('Num_GPUs:{}, List:{}'.format(len(physical_devices), physical_devices))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5-6x854zxem"
      },
      "source": [
        "## Inverted Residual Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "KGjTG3kAzxem",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "def _inverted_res_block(inputs, expansion, filters, strides):\n",
        "    x = inputs\n",
        "    in_chnls = inputs.shape[-1]\n",
        "    # Expansion\n",
        "    if expansion != 1:\n",
        "        x = Conv2D(kernel_size=1, filters=in_chnls * expansion, strides=1, padding='same', use_bias=False, kernel_regularizer=l2(4e-5))(x)\n",
        "        x = BatchNormalization(momentum=0.999, epsilon=0.001)(x)\n",
        "        x = ReLU(max_value=6)(x)\n",
        "        x = Dropout(0.2)(x)\n",
        "\n",
        "    # Depthwise convolution\n",
        "    x = DepthwiseConv2D(kernel_size=3, strides=strides, padding='same', use_bias=False, depthwise_regularizer=l2(4e-5))(x)\n",
        "    x = BatchNormalization(momentum=0.999, epsilon=0.001)(x)\n",
        "    x = ReLU(max_value=6)(x)\n",
        "\n",
        "    # Linear bottleneck\n",
        "    x = Conv2D(kernel_size=1, filters=filters, strides=1, padding='same', use_bias=False, kernel_regularizer=l2(4e-5))(x)\n",
        "    x = BatchNormalization(momentum=0.999, epsilon=0.001)(x)\n",
        "    # No activation\n",
        "    \n",
        "    # Residual connection\n",
        "    if in_chnls == filters and strides == 1:\n",
        "        x = Add()([inputs, x])\n",
        "        \n",
        "    return x #return output of layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBNLdmgTzxen"
      },
      "source": [
        "## MobileNetV2 변형 구현"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "5TkdqcFRzxen",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "def MobileNetV2plus(input_shape, classes):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    \n",
        "    ### Q2. Modify MobileNetV2 ###\n",
        "    # 32x32x3 - conv3\n",
        "    x = Conv2D(filters=32, kernel_size=3, strides=2, padding='same')(inputs)\n",
        "    x = BatchNormalization(momentum=0.999, epsilon=0.001)(x)\n",
        "    x = ReLU(max_value=6)(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    # 16x16x32 - resblock\n",
        "    x = _inverted_res_block(inputs=x, expansion=1, filters=16, strides=1)\n",
        "\n",
        "    # 16x16x16 - resblock\n",
        "    x = _inverted_res_block(inputs=x, expansion=6, filters=24, strides=2)\n",
        "    x = _inverted_res_block(inputs=x, expansion=6, filters=24, strides=1)\n",
        "    \n",
        "    # 8x8x24 - resblock\n",
        "    x = _inverted_res_block(inputs=x, expansion=6, filters=32, strides=2)\n",
        "    x = _inverted_res_block(inputs=x, expansion=6, filters=32, strides=1)\n",
        "    x = _inverted_res_block(inputs=x, expansion=6, filters=32, strides=1)\n",
        "    \n",
        "    # 4x4x32 - resblock\n",
        "    x = _inverted_res_block(inputs=x, expansion=6, filters=64, strides=2)\n",
        "    x = _inverted_res_block(inputs=x, expansion=6, filters=64, strides=1)\n",
        "    x = _inverted_res_block(inputs=x, expansion=6, filters=64, strides=1)\n",
        "    x = _inverted_res_block(inputs=x, expansion=6, filters=64, strides=1)\n",
        "    \n",
        "    # 2x2x64 - resblock\n",
        "    x = _inverted_res_block(inputs=x, expansion=6, filters=96, strides=1)\n",
        "    x = _inverted_res_block(inputs=x, expansion=6, filters=96, strides=1)\n",
        "    x = _inverted_res_block(inputs=x, expansion=6, filters=96, strides=1)\n",
        "\n",
        "    # 2x2x96 - resblock\n",
        "    x = _inverted_res_block(inputs=x, expansion=6, filters=160, strides=2)\n",
        "    x = _inverted_res_block(inputs=x, expansion=6, filters=160, strides=1)\n",
        "    x = _inverted_res_block(inputs=x, expansion=6, filters=160, strides=1)\n",
        "\n",
        "    # last inverted_resblock(modified)\n",
        "    x = Conv2D(kernel_size=1, filters=160 * 6, strides=1, padding='same', use_bias=False, kernel_regularizer=l2(4e-5))(x)\n",
        "    x = BatchNormalization(momentum=0.999, epsilon=0.001)(x)\n",
        "    x = ReLU()(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    # avg pool\n",
        "    x = AveragePooling2D(pool_size=x.shape[1])(x)\n",
        "\n",
        "    # conv1\n",
        "    x = Conv2D(filters=1280, kernel_size=1, strides=1)(x)\n",
        "    x = ReLU(max_value=6)(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    # output\n",
        "    outputs = Dense(classes, activation='softmax')(x)\n",
        "    ##############################\n",
        "                                    \n",
        "    return Model(inputs=inputs, outputs=outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "1LvkStJhzxeo",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "my_mobilenet = MobileNetV2plus(input_shape=(32,32,3),classes=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jak1sYDXY8Fe",
        "outputId": "d1a76417-ba10-4632-9e40-113d00cc6081"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 16, 16, 32)   896         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 16, 16, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " re_lu (ReLU)                   (None, 16, 16, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 16, 16, 32)   0           ['re_lu[0][0]']                  \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 16, 16, 32)  288         ['dropout[0][0]']                \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 16, 16, 32)  128         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_1 (ReLU)                 (None, 16, 16, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 16, 16, 16)   512         ['re_lu_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 16, 16, 16)  64          ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 16, 16, 96)   1536        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 16, 16, 96)  384         ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_2 (ReLU)                 (None, 16, 16, 96)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 16, 16, 96)   0           ['re_lu_2[0][0]']                \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 8, 8, 96)    864         ['dropout_1[0][0]']              \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 8, 8, 96)    384         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_3 (ReLU)                 (None, 8, 8, 96)     0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 8, 8, 24)     2304        ['re_lu_3[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 8, 8, 24)    96          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 8, 8, 144)    3456        ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 8, 8, 144)   576         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_4 (ReLU)                 (None, 8, 8, 144)    0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 8, 8, 144)    0           ['re_lu_4[0][0]']                \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 8, 8, 144)   1296        ['dropout_2[0][0]']              \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 8, 8, 144)   576         ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_5 (ReLU)                 (None, 8, 8, 144)    0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 8, 8, 24)     3456        ['re_lu_5[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 8, 8, 24)    96          ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 8, 8, 24)     0           ['batch_normalization_5[0][0]',  \n",
            "                                                                  'batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 8, 8, 144)    3456        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 8, 8, 144)   576         ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_6 (ReLU)                 (None, 8, 8, 144)    0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 8, 8, 144)    0           ['re_lu_6[0][0]']                \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 4, 4, 144)   1296        ['dropout_3[0][0]']              \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 4, 4, 144)   576         ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_7 (ReLU)                 (None, 4, 4, 144)    0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 4, 4, 32)     4608        ['re_lu_7[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 4, 4, 32)    128         ['conv2d_7[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 4, 4, 192)    6144        ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 4, 4, 192)   768         ['conv2d_8[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_8 (ReLU)                 (None, 4, 4, 192)    0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 4, 4, 192)    0           ['re_lu_8[0][0]']                \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 4, 4, 192)   1728        ['dropout_4[0][0]']              \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 4, 4, 192)   768         ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_9 (ReLU)                 (None, 4, 4, 192)    0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 4, 4, 32)     6144        ['re_lu_9[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 4, 4, 32)    128         ['conv2d_9[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 4, 4, 32)     0           ['batch_normalization_11[0][0]', \n",
            "                                                                  'batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 4, 4, 192)    6144        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 4, 4, 192)   768         ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_10 (ReLU)                (None, 4, 4, 192)    0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 4, 4, 192)    0           ['re_lu_10[0][0]']               \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 4, 4, 192)   1728        ['dropout_5[0][0]']              \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 4, 4, 192)   768         ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_11 (ReLU)                (None, 4, 4, 192)    0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 4, 4, 32)     6144        ['re_lu_11[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 4, 4, 32)    128         ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 4, 4, 32)     0           ['add_1[0][0]',                  \n",
            "                                                                  'batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 4, 4, 192)    6144        ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 4, 4, 192)   768         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_12 (ReLU)                (None, 4, 4, 192)    0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 4, 4, 192)    0           ['re_lu_12[0][0]']               \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 2, 2, 192)   1728        ['dropout_6[0][0]']              \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 2, 2, 192)   768         ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_13 (ReLU)                (None, 2, 2, 192)    0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 2, 2, 64)     12288       ['re_lu_13[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 2, 2, 64)    256         ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 2, 2, 384)    24576       ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 2, 2, 384)   1536        ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_14 (ReLU)                (None, 2, 2, 384)    0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, 2, 2, 384)    0           ['re_lu_14[0][0]']               \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 2, 2, 384)   3456        ['dropout_7[0][0]']              \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 2, 2, 384)   1536        ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_15 (ReLU)                (None, 2, 2, 384)    0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 2, 2, 64)     24576       ['re_lu_15[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 2, 2, 64)    256         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 2, 2, 64)     0           ['batch_normalization_20[0][0]', \n",
            "                                                                  'batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 2, 2, 384)    24576       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 2, 2, 384)   1536        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_16 (ReLU)                (None, 2, 2, 384)    0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)            (None, 2, 2, 384)    0           ['re_lu_16[0][0]']               \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 2, 2, 384)   3456        ['dropout_8[0][0]']              \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 2, 2, 384)   1536        ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_17 (ReLU)                (None, 2, 2, 384)    0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 2, 2, 64)     24576       ['re_lu_17[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 2, 2, 64)    256         ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 2, 2, 64)     0           ['add_3[0][0]',                  \n",
            "                                                                  'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 2, 2, 384)    24576       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 2, 2, 384)   1536        ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_18 (ReLU)                (None, 2, 2, 384)    0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)            (None, 2, 2, 384)    0           ['re_lu_18[0][0]']               \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 2, 2, 384)   3456        ['dropout_9[0][0]']              \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 2, 2, 384)   1536        ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_19 (ReLU)                (None, 2, 2, 384)    0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 2, 2, 64)     24576       ['re_lu_19[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 2, 2, 64)    256         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 2, 2, 64)     0           ['add_4[0][0]',                  \n",
            "                                                                  'batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 2, 2, 384)    24576       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 2, 2, 384)   1536        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_20 (ReLU)                (None, 2, 2, 384)    0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_10 (Dropout)           (None, 2, 2, 384)    0           ['re_lu_20[0][0]']               \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 2, 2, 384)   3456        ['dropout_10[0][0]']             \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 2, 2, 384)   1536        ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_21 (ReLU)                (None, 2, 2, 384)    0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 2, 2, 96)     36864       ['re_lu_21[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 2, 2, 96)    384         ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 2, 2, 576)    55296       ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 2, 2, 576)   2304        ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_22 (ReLU)                (None, 2, 2, 576)    0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_11 (Dropout)           (None, 2, 2, 576)    0           ['re_lu_22[0][0]']               \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 2, 2, 576)   5184        ['dropout_11[0][0]']             \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 2, 2, 576)   2304        ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_23 (ReLU)                (None, 2, 2, 576)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 2, 2, 96)     55296       ['re_lu_23[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 2, 2, 96)    384         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 2, 2, 96)     0           ['batch_normalization_32[0][0]', \n",
            "                                                                  'batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 2, 2, 576)    55296       ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 2, 2, 576)   2304        ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_24 (ReLU)                (None, 2, 2, 576)    0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_12 (Dropout)           (None, 2, 2, 576)    0           ['re_lu_24[0][0]']               \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 2, 2, 576)   5184        ['dropout_12[0][0]']             \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 2, 2, 576)   2304        ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_25 (ReLU)                (None, 2, 2, 576)    0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 2, 2, 96)     55296       ['re_lu_25[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 2, 2, 96)    384         ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 2, 2, 96)     0           ['add_6[0][0]',                  \n",
            "                                                                  'batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 2, 2, 576)    55296       ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 2, 2, 576)   2304        ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_26 (ReLU)                (None, 2, 2, 576)    0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_13 (Dropout)           (None, 2, 2, 576)    0           ['re_lu_26[0][0]']               \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 1, 1, 576)   5184        ['dropout_13[0][0]']             \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 1, 1, 576)   2304        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_27 (ReLU)                (None, 1, 1, 576)    0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 1, 1, 160)    92160       ['re_lu_27[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 1, 1, 160)   640         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 1, 1, 960)    153600      ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 1, 1, 960)   3840        ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_28 (ReLU)                (None, 1, 1, 960)    0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_14 (Dropout)           (None, 1, 1, 960)    0           ['re_lu_28[0][0]']               \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 1, 1, 960)   8640        ['dropout_14[0][0]']             \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 1, 1, 960)   3840        ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_29 (ReLU)                (None, 1, 1, 960)    0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 1, 1, 160)    153600      ['re_lu_29[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 1, 1, 160)   640         ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 1, 1, 160)    0           ['batch_normalization_41[0][0]', \n",
            "                                                                  'batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 1, 1, 960)    153600      ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 1, 1, 960)   3840        ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_30 (ReLU)                (None, 1, 1, 960)    0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_15 (Dropout)           (None, 1, 1, 960)    0           ['re_lu_30[0][0]']               \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 1, 1, 960)   8640        ['dropout_15[0][0]']             \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 1, 1, 960)   3840        ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_31 (ReLU)                (None, 1, 1, 960)    0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 1, 1, 160)    153600      ['re_lu_31[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 1, 1, 160)   640         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 1, 1, 160)    0           ['add_8[0][0]',                  \n",
            "                                                                  'batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 1, 1, 960)    153600      ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 1, 1, 960)   3840        ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_32 (ReLU)                (None, 1, 1, 960)    0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_16 (Dropout)           (None, 1, 1, 960)    0           ['re_lu_32[0][0]']               \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 1, 1, 960)   0           ['dropout_16[0][0]']             \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 1, 1, 1280)   1230080     ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " re_lu_33 (ReLU)                (None, 1, 1, 1280)   0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_17 (Dropout)           (None, 1, 1, 1280)   0           ['re_lu_33[0][0]']               \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 1280)         0           ['dropout_17[0][0]']             \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 10)           12810       ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,765,226\n",
            "Trainable params: 2,736,234\n",
            "Non-trainable params: 28,992\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "my_mobilenet.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O69GTfOTzxeo"
      },
      "source": [
        "## Training Data\n",
        "\n",
        "- keras dataset 혹은 tensorflow dataset 이용\n",
        "- train data를 9:1로 나눠서 validation data로 이용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azOxenuyzxep",
        "outputId": "252626ed-9082-4298-9416-5cd06d85505a",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 13s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "#Load data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "#Split train set into train/valid set\n",
        "from sklearn import model_selection\n",
        "x_train, x_valid, y_train, y_valid = model_selection.train_test_split(x_train, y_train,test_size=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1R87-fgzxep"
      },
      "source": [
        "## Data Preprocessing\n",
        "자유롭게 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ZYETZHz1zxep",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "### Q3. Preporcessing ###\n",
        "x_train = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)(x_train)\n",
        "x_valid = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)(x_valid)\n",
        "x_test = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)(x_test)\n",
        "#########################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6BOLhxLzxep"
      },
      "source": [
        "## Model Compile\n",
        "loss function, optimizer 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "5kti2fkFzxep",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "### Q4. Model compile ###\n",
        "my_mobilenet.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                     loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "#########################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "DSOCZ5ctzxeq",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "### Q5. Callbacks ###\n",
        "callbacks = []\n",
        "\n",
        "def decay(epoch):\n",
        "    ####### 실습 #######\n",
        "    if epoch < 5:\n",
        "        return 0.0005\n",
        "    else:\n",
        "        return 0.001\n",
        "\n",
        "#callbacks.append(tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1))\n",
        "#callbacks.append(tf.keras.callbacks.LearningRateScheduler(decay))\n",
        "#####################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2w6KyPvzxeq"
      },
      "source": [
        "## Model Training\n",
        "hyperparameter를 적절히 설정한다. (epochs 등..)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nOCP5xxzxeq",
        "outputId": "64d1ff64-a9c8-416e-bc35-8ee64f79122a",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "704/704 [==============================] - 23s 24ms/step - loss: 2.2245 - accuracy: 0.2162 - val_loss: 2.4789 - val_accuracy: 0.0974\n",
            "Epoch 2/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 1.8422 - accuracy: 0.3600 - val_loss: 2.5038 - val_accuracy: 0.0974\n",
            "Epoch 3/100\n",
            "704/704 [==============================] - 16s 22ms/step - loss: 1.7023 - accuracy: 0.4185 - val_loss: 2.4670 - val_accuracy: 0.0974\n",
            "Epoch 4/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 1.5914 - accuracy: 0.4685 - val_loss: 2.4733 - val_accuracy: 0.0996\n",
            "Epoch 5/100\n",
            "704/704 [==============================] - 15s 22ms/step - loss: 1.4967 - accuracy: 0.5058 - val_loss: 2.4374 - val_accuracy: 0.1004\n",
            "Epoch 6/100\n",
            "704/704 [==============================] - 15s 22ms/step - loss: 1.4191 - accuracy: 0.5359 - val_loss: 2.2692 - val_accuracy: 0.1862\n",
            "Epoch 7/100\n",
            "704/704 [==============================] - 15s 22ms/step - loss: 1.3557 - accuracy: 0.5619 - val_loss: 1.8492 - val_accuracy: 0.3756\n",
            "Epoch 8/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 1.3043 - accuracy: 0.5785 - val_loss: 1.4827 - val_accuracy: 0.5432\n",
            "Epoch 9/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 1.2495 - accuracy: 0.5960 - val_loss: 2.2018 - val_accuracy: 0.4536\n",
            "Epoch 10/100\n",
            "704/704 [==============================] - 15s 22ms/step - loss: 1.2113 - accuracy: 0.6107 - val_loss: 1.9306 - val_accuracy: 0.4902\n",
            "Epoch 11/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 1.2356 - accuracy: 0.6044 - val_loss: 1.8287 - val_accuracy: 0.5174\n",
            "Epoch 12/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 1.1503 - accuracy: 0.6299 - val_loss: 1.2852 - val_accuracy: 0.6214\n",
            "Epoch 13/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 1.1135 - accuracy: 0.6448 - val_loss: 1.6734 - val_accuracy: 0.5392\n",
            "Epoch 14/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 1.0887 - accuracy: 0.6556 - val_loss: 1.1559 - val_accuracy: 0.6506\n",
            "Epoch 15/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 1.0708 - accuracy: 0.6617 - val_loss: 0.9981 - val_accuracy: 0.6982\n",
            "Epoch 16/100\n",
            "704/704 [==============================] - 15s 22ms/step - loss: 1.0580 - accuracy: 0.6670 - val_loss: 1.0009 - val_accuracy: 0.7034\n",
            "Epoch 17/100\n",
            "704/704 [==============================] - 15s 22ms/step - loss: 1.0390 - accuracy: 0.6753 - val_loss: 1.0290 - val_accuracy: 0.6896\n",
            "Epoch 18/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 1.0020 - accuracy: 0.6866 - val_loss: 1.0520 - val_accuracy: 0.6786\n",
            "Epoch 19/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.9847 - accuracy: 0.6966 - val_loss: 0.8940 - val_accuracy: 0.7338\n",
            "Epoch 20/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.9858 - accuracy: 0.6966 - val_loss: 1.1183 - val_accuracy: 0.6842\n",
            "Epoch 21/100\n",
            "704/704 [==============================] - 15s 22ms/step - loss: 0.9709 - accuracy: 0.7029 - val_loss: 0.9267 - val_accuracy: 0.7206\n",
            "Epoch 22/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.9597 - accuracy: 0.7056 - val_loss: 0.9456 - val_accuracy: 0.7244\n",
            "Epoch 23/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.9542 - accuracy: 0.7121 - val_loss: 1.4398 - val_accuracy: 0.6020\n",
            "Epoch 24/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 1.0336 - accuracy: 0.6831 - val_loss: 0.9601 - val_accuracy: 0.7144\n",
            "Epoch 25/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.9364 - accuracy: 0.7174 - val_loss: 0.8630 - val_accuracy: 0.7458\n",
            "Epoch 26/100\n",
            "704/704 [==============================] - 15s 22ms/step - loss: 0.9208 - accuracy: 0.7218 - val_loss: 0.9103 - val_accuracy: 0.7300\n",
            "Epoch 27/100\n",
            "704/704 [==============================] - 15s 22ms/step - loss: 0.9242 - accuracy: 0.7251 - val_loss: 0.8968 - val_accuracy: 0.7286\n",
            "Epoch 28/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.9249 - accuracy: 0.7225 - val_loss: 0.9062 - val_accuracy: 0.7244\n",
            "Epoch 29/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.8760 - accuracy: 0.7396 - val_loss: 0.8194 - val_accuracy: 0.7442\n",
            "Epoch 30/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.9063 - accuracy: 0.7321 - val_loss: 0.9793 - val_accuracy: 0.7126\n",
            "Epoch 31/100\n",
            "704/704 [==============================] - 15s 22ms/step - loss: 0.8850 - accuracy: 0.7391 - val_loss: 1.2710 - val_accuracy: 0.6318\n",
            "Epoch 32/100\n",
            "704/704 [==============================] - 15s 22ms/step - loss: 0.8903 - accuracy: 0.7362 - val_loss: 0.8590 - val_accuracy: 0.7492\n",
            "Epoch 33/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.8487 - accuracy: 0.7507 - val_loss: 0.9485 - val_accuracy: 0.7186\n",
            "Epoch 34/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.9958 - accuracy: 0.7031 - val_loss: 1.0229 - val_accuracy: 0.7160\n",
            "Epoch 35/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.8824 - accuracy: 0.7420 - val_loss: 0.8175 - val_accuracy: 0.7670\n",
            "Epoch 36/100\n",
            "704/704 [==============================] - 15s 22ms/step - loss: 0.8502 - accuracy: 0.7510 - val_loss: 0.8188 - val_accuracy: 0.7564\n",
            "Epoch 37/100\n",
            "704/704 [==============================] - 15s 22ms/step - loss: 0.8440 - accuracy: 0.7548 - val_loss: 0.8698 - val_accuracy: 0.7360\n",
            "Epoch 38/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.9275 - accuracy: 0.7290 - val_loss: 0.9695 - val_accuracy: 0.7224\n",
            "Epoch 39/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.9090 - accuracy: 0.7368 - val_loss: 0.8301 - val_accuracy: 0.7742\n",
            "Epoch 40/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.9342 - accuracy: 0.7278 - val_loss: 0.9635 - val_accuracy: 0.7126\n",
            "Epoch 41/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.9275 - accuracy: 0.7282 - val_loss: 0.9281 - val_accuracy: 0.7298\n",
            "Epoch 42/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.9494 - accuracy: 0.7256 - val_loss: 3.1210 - val_accuracy: 0.3736\n",
            "Epoch 43/100\n",
            "704/704 [==============================] - 15s 22ms/step - loss: 1.1099 - accuracy: 0.6709 - val_loss: 1.5353 - val_accuracy: 0.5422\n",
            "Epoch 44/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 1.0926 - accuracy: 0.6766 - val_loss: 1.1093 - val_accuracy: 0.6668\n",
            "Epoch 45/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 1.0507 - accuracy: 0.6910 - val_loss: 1.4270 - val_accuracy: 0.6090\n",
            "Epoch 46/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.9660 - accuracy: 0.7212 - val_loss: 0.9272 - val_accuracy: 0.7480\n",
            "Epoch 47/100\n",
            "704/704 [==============================] - 16s 22ms/step - loss: 0.9001 - accuracy: 0.7458 - val_loss: 0.8332 - val_accuracy: 0.7602\n",
            "Epoch 48/100\n",
            "704/704 [==============================] - 15s 22ms/step - loss: 0.8896 - accuracy: 0.7469 - val_loss: 0.9982 - val_accuracy: 0.7204\n",
            "Epoch 49/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 1.0087 - accuracy: 0.7095 - val_loss: 0.9746 - val_accuracy: 0.7242\n",
            "Epoch 50/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.9017 - accuracy: 0.7429 - val_loss: 0.9281 - val_accuracy: 0.7342\n",
            "Epoch 51/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.8477 - accuracy: 0.7618 - val_loss: 0.7959 - val_accuracy: 0.7716\n",
            "Epoch 52/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.8268 - accuracy: 0.7667 - val_loss: 0.7759 - val_accuracy: 0.7750\n",
            "Epoch 53/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.8582 - accuracy: 0.7551 - val_loss: 0.8162 - val_accuracy: 0.7640\n",
            "Epoch 54/100\n",
            "704/704 [==============================] - 15s 22ms/step - loss: 0.8357 - accuracy: 0.7633 - val_loss: 0.7795 - val_accuracy: 0.7804\n",
            "Epoch 55/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.8158 - accuracy: 0.7697 - val_loss: 0.8095 - val_accuracy: 0.7724\n",
            "Epoch 56/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.8161 - accuracy: 0.7705 - val_loss: 0.8064 - val_accuracy: 0.7678\n",
            "Epoch 57/100\n",
            "704/704 [==============================] - 16s 22ms/step - loss: 1.2076 - accuracy: 0.6399 - val_loss: 1.2537 - val_accuracy: 0.6636\n",
            "Epoch 58/100\n",
            "704/704 [==============================] - 15s 22ms/step - loss: 0.9406 - accuracy: 0.7328 - val_loss: 1.0138 - val_accuracy: 0.7218\n",
            "Epoch 59/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.9019 - accuracy: 0.7466 - val_loss: 1.0332 - val_accuracy: 0.7128\n",
            "Epoch 60/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.8773 - accuracy: 0.7535 - val_loss: 1.0247 - val_accuracy: 0.7028\n",
            "Epoch 61/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.8571 - accuracy: 0.7587 - val_loss: 0.8071 - val_accuracy: 0.7802\n",
            "Epoch 62/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.8332 - accuracy: 0.7686 - val_loss: 1.0225 - val_accuracy: 0.7062\n",
            "Epoch 63/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.8239 - accuracy: 0.7718 - val_loss: 0.8402 - val_accuracy: 0.7616\n",
            "Epoch 64/100\n",
            "704/704 [==============================] - 15s 22ms/step - loss: 0.8157 - accuracy: 0.7742 - val_loss: 0.8166 - val_accuracy: 0.7696\n",
            "Epoch 65/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.7974 - accuracy: 0.7777 - val_loss: 0.7493 - val_accuracy: 0.7898\n",
            "Epoch 66/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.8614 - accuracy: 0.7590 - val_loss: 2.8114 - val_accuracy: 0.4382\n",
            "Epoch 67/100\n",
            "704/704 [==============================] - 15s 22ms/step - loss: 0.8409 - accuracy: 0.7639 - val_loss: 0.9011 - val_accuracy: 0.7466\n",
            "Epoch 68/100\n",
            "704/704 [==============================] - 16s 22ms/step - loss: 0.8261 - accuracy: 0.7690 - val_loss: 1.1808 - val_accuracy: 0.6488\n",
            "Epoch 69/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.9604 - accuracy: 0.7245 - val_loss: 1.0148 - val_accuracy: 0.7060\n",
            "Epoch 70/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.9427 - accuracy: 0.7324 - val_loss: 0.8476 - val_accuracy: 0.7702\n",
            "Epoch 71/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.9074 - accuracy: 0.7440 - val_loss: 0.9505 - val_accuracy: 0.7338\n",
            "Epoch 72/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.8933 - accuracy: 0.7472 - val_loss: 0.8668 - val_accuracy: 0.7640\n",
            "Epoch 73/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.8379 - accuracy: 0.7687 - val_loss: 0.7989 - val_accuracy: 0.7830\n",
            "Epoch 74/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.8641 - accuracy: 0.7592 - val_loss: 1.0415 - val_accuracy: 0.7134\n",
            "Epoch 75/100\n",
            "704/704 [==============================] - 15s 22ms/step - loss: 0.8308 - accuracy: 0.7725 - val_loss: 0.7566 - val_accuracy: 0.7958\n",
            "Epoch 76/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.7900 - accuracy: 0.7844 - val_loss: 0.7944 - val_accuracy: 0.7790\n",
            "Epoch 77/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.7965 - accuracy: 0.7803 - val_loss: 0.7661 - val_accuracy: 0.7810\n",
            "Epoch 78/100\n",
            "704/704 [==============================] - 16s 22ms/step - loss: 0.7934 - accuracy: 0.7815 - val_loss: 0.7847 - val_accuracy: 0.7776\n",
            "Epoch 79/100\n",
            "704/704 [==============================] - 16s 22ms/step - loss: 0.7818 - accuracy: 0.7841 - val_loss: 0.8977 - val_accuracy: 0.7392\n",
            "Epoch 80/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.7875 - accuracy: 0.7818 - val_loss: 0.7882 - val_accuracy: 0.7906\n",
            "Epoch 81/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.7848 - accuracy: 0.7847 - val_loss: 0.7327 - val_accuracy: 0.7992\n",
            "Epoch 82/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.7881 - accuracy: 0.7820 - val_loss: 0.7322 - val_accuracy: 0.8000\n",
            "Epoch 83/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.8290 - accuracy: 0.7692 - val_loss: 0.8536 - val_accuracy: 0.7620\n",
            "Epoch 84/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.8393 - accuracy: 0.7663 - val_loss: 0.8555 - val_accuracy: 0.7788\n",
            "Epoch 85/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.8737 - accuracy: 0.7571 - val_loss: 0.9751 - val_accuracy: 0.7258\n",
            "Epoch 86/100\n",
            "704/704 [==============================] - 15s 22ms/step - loss: 0.9772 - accuracy: 0.7222 - val_loss: 0.9120 - val_accuracy: 0.7470\n",
            "Epoch 87/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.8548 - accuracy: 0.7645 - val_loss: 0.8724 - val_accuracy: 0.7584\n",
            "Epoch 88/100\n",
            "704/704 [==============================] - 16s 22ms/step - loss: 0.8093 - accuracy: 0.7809 - val_loss: 0.7629 - val_accuracy: 0.7912\n",
            "Epoch 89/100\n",
            "704/704 [==============================] - 15s 22ms/step - loss: 0.8074 - accuracy: 0.7791 - val_loss: 0.9515 - val_accuracy: 0.7122\n",
            "Epoch 90/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.8829 - accuracy: 0.7556 - val_loss: 0.8152 - val_accuracy: 0.7828\n",
            "Epoch 91/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.8497 - accuracy: 0.7663 - val_loss: 0.8451 - val_accuracy: 0.7650\n",
            "Epoch 92/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.8341 - accuracy: 0.7692 - val_loss: 0.8404 - val_accuracy: 0.7648\n",
            "Epoch 93/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.8589 - accuracy: 0.7625 - val_loss: 0.8269 - val_accuracy: 0.7758\n",
            "Epoch 94/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.8457 - accuracy: 0.7658 - val_loss: 0.8186 - val_accuracy: 0.7824\n",
            "Epoch 95/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.7917 - accuracy: 0.7866 - val_loss: 0.7407 - val_accuracy: 0.8016\n",
            "Epoch 96/100\n",
            "704/704 [==============================] - 15s 21ms/step - loss: 0.8812 - accuracy: 0.7569 - val_loss: 0.8677 - val_accuracy: 0.7686\n",
            "Epoch 97/100\n",
            "704/704 [==============================] - 15s 22ms/step - loss: 0.8144 - accuracy: 0.7787 - val_loss: 0.7536 - val_accuracy: 0.7984\n",
            "Epoch 98/100\n",
            "704/704 [==============================] - 16s 22ms/step - loss: 0.9504 - accuracy: 0.7334 - val_loss: 1.5090 - val_accuracy: 0.6264\n",
            "Epoch 99/100\n",
            "704/704 [==============================] - 16s 22ms/step - loss: 0.8709 - accuracy: 0.7618 - val_loss: 0.7985 - val_accuracy: 0.7942\n",
            "Epoch 100/100\n",
            "704/704 [==============================] - 15s 22ms/step - loss: 0.8149 - accuracy: 0.7792 - val_loss: 0.7496 - val_accuracy: 0.8050\n"
          ]
        }
      ],
      "source": [
        "### Q6. Training ###\n",
        "history = my_mobilenet.fit(x_train, y_train, batch_size=64, \n",
        "                          epochs= 100,\n",
        "                          callbacks=callbacks,              \n",
        "                          validation_data=(x_valid, y_valid))\n",
        "####################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WzvdkTkzxeq"
      },
      "source": [
        "## 참고용\n",
        "조교가 학습한 모델의 validation accuracy를 그래프로 나타내 보았다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcd2exS-zxeq",
        "outputId": "9dc6b7ab-535f-40ee-f643-4ea62206c140",
        "scrolled": false
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Validation Accuracy', fontsize=15)\n",
        "plt.xlabel('epochs', fontsize=15)\n",
        "plt.ylabel('Acc.', fontsize=15)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "vc8h7Je3pD94",
        "outputId": "1e8f95e8-2da7-4e3e-d3d8-dadadfb886ff"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEdCAYAAADn46tbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd5xcZb3/39+Z2d6yLXWzaQRCaAmEFqQIKKAIWFByLWAB/Snq1WtBrxexX/u1cAsqdkBE1ChRSgQBpSQhjfSQtrtJtu/OtpnZmXl+f5xzZqdunZ3dzHzfr9e+suecZ+Y8M2dzPudbHzHGoCiKoijRuKZ6AoqiKMr0Q8VBURRFSUDFQVEURUlAxUFRFEVJQMVBURRFSUDFQVEURUlAxUEZFyLyJxHZPszxH4pIl4gUjOK9LhMRIyKnR+0zInL7CK+71h63cIxz/5SIXJZk/4jnnAxE5Bb73L/K9LkVJRUqDsp4uR84XUSWxx8QETfwFuBhY4x/nO9/IfDbCcxvOD4FXJbhcw7HGvvf60WkaArOrygJqDgo4+WPQD9DN7ZoXg3MwhKQcWGMed4Y0zze158o5xSRmcAVwHqgFHhDJs8/HCpUuY2KgzIujDF9wJ+AtyU5fBPQAvxNRJaJyAMi0iAi/SKyQ0T+VUSG/duLd/GIxV0i0iIiPSLyC6A8yev+U0S2i0iviDSKyK9FZHbU8UNANfB5+xzGcTElcyuJyO0isk9E/CKyX0Q+Fnf8LhFpE5GVIvK8/Rk3i8jFw3+DEW4E3MDtQBNJxFZEikTkGyJy2J7HQRH5WtyYW+3P7RORZhF5SEQq7GNPichDceNjXHkistDefruI/EJEurCuLyLyLhF5VkQ6RKRTRJ4UkVVJ5nmJfaxXRLrt864UkSp7XrfEjRcROSAi3x3ld6VkEBUHZSLcDywVkXOcHSKSB7wJeNAYEwLmAXuADwKvA34EfAH49BjP9RHgTuAeLJfVAPCNJONmAl8FXg/8K7AYS6Scv/U3At3AT7DcSBcCLyU7oYjcCvwAWIv1RP9b4Nsickfc0GLg58D/AW8G/MDDIlI8is+1BthsjNkN/Aa4xrmp23MQLCvt/wF3Y32HnwdqosZ8zj7334Eb7LHdWJbIWPkW0IMlWl+19y0EfmHv+xegAXhGRBZHzeEyLOtnELgZ66HhGWCeMaYD+D1wS9y5LgMWAfeOY57KZGOM0R/9GdcPkA90At+M2nctYIDVScYL4AE+CxyI2n+Z/ZrTo/YZ4Hb7dzdwFPifuPd73B63MMX83FjiZIBLova3AXclGR99ThfWk/xP48b8N9aNt9Devst+3eVRY1bY+64e4furB8LAp+ztVfbr3h015ip733Up3mMGlnvvO8Oc5yngobh9Md85lgAY4PcjzNllX8PdwJ1R+58DNgKS4nVX2p91cdS+XwAbp/rvWH+S/6jloIwbY0wAeBh4q/2EC9YT42GsmwUiUigiXxCR/VhP1IPAV4BFIuIZ5anmA3OwnqCjeTh+oIhcIyL/FJFuIAg02odOHv0nA6AOmEtigPo3WO6sM6L2BbBuwA47o95jOG6Kek+MMRuB/cS6li4HOowxa1O8x4VAEfDTEc41Wh6J3yEip4rI70WkGQhhXcNTsL9TESkBzgd+buy7fhLWY/1d3Gy/pgzLykrXvJU0o+KgTJT7sZ6ALxSRQuB64IGom8TXgU9guYNeB5wLfNk+VjjKczgxg5a4/THbInIulguoEXgn1o3zgjGey2GO/W98gNrZrora12OMCTsbtmiO5pxrsFxa3SIyQ0RmYM3/chGZZY+pBo4N8x7V9r/DjRkLMZ/Xvok/hiXQHwcuxrqGWxn6fJVYVmHKOdh/Dz8FbrYfJN6KZdndl6Z5K2lmtE9uipKKJ7FuKDdh3VDLiM1SuhH4gTEmEh8QkdeP8RzH7X9nxu2P334j0Aq8zREnEVkwxnM5ODe6+HM4N+2Ocb4vACKyDMv9BJZrLp4bgR8C7QwJVTLa7X/nYLnLkuHDcgFGU5libPyT/4VYFtBrjBUXASA6LoI1//AI8wRLHD6Plc12C/AHY0yyz65MA9RyUCaEsYLODzIUrNxljNkaNaQIy50ERGogbmJsNGAJxPVx+98Ut10EDMa5Nt6e5P0CjPxU34gV57gxbv9bAS+QsgBwlKzBctG8HutmGf2zjSHX0nqgSkSuTfE+z2EF528e5lyNwLK4fa8d5TyddNboa7gaK0YBRDLXXgDeFeVeTMAY04BlhXwBeBXqUprWqOWgpIP7gQ9jPbl/Pu7Y48CH7JhDB/AhYMSq6WiMMSER+QbwLRFpw8qCeTNwapJz/auI/BdWGuZq4B1J3nI38HoR+SvQC+wxxvTEnTMsIncB/yci7fZ7X4qVCfRZY4xvLJ8hCWuAx40x6+IPiMjPsT7rAvu8jwL3icgXsdxQc7AC7O83xnSJyJeAr4hIPrAO6/t9PfAFY0wTVqbQe+2U0UewBOjqUc7zeazv6Ef2NajDCsI3xY27A3gC+IuI3AP0YVkdG40xf44a9xOsOE6j/dmU6cpUR8T1Jzt+gINYLomT4vbPwro5ebHcT98AbrXHltpjLmOYbCV7W4AvYbmNeoBfY1kqMdlKWNXPDVg3pyeApUne6xysm16ffeyyZOe0930YK0gcAA4AH4s7fhfQluT7SHivuPMb4F9SHJ+DFUz/tL1dhJVi2oj1BH8Q+Erca96PFQj3Y1lZDwLlUcc/Y38vPcCvgOtInq10bZL5XA28jGWhbMOKHT1FYgbUpcDTWNlTXVguxxVxYwqxAtpfnuq/Wf0Z/kfsC6YoijLpiMjrgD8DJxtj9k/1fJTUqDgoijLpiMhcLCvuB8ARY0yqGIoyTdCAtKIomeA2rOC6D8tVp0xz1HJQFEVRElDLQVEURUkgK1JZa2pqzMKFC6d6GoqiKCcUmzZtajPG1CY7lhXisHDhQjZu3DjV01AURTmhEJHDqY6pW0lRFEVJQMVBURRFSUDFQVEURUlAxUFRFEVJQMVBURRFSUDFQVEURUkg4+IgIleLyB4R2Z9koXZEpF5EnhSRzSKyzW7UpSiKomSQjIqDvdDL3cA1wHJgjYgsjxv2OeBBY8xKrEVh/juTc1QURTkRCIbCfHXdLo52DUzK+2facjgP2G+MOWCsdXYfIHF1L4O1gDtABdZqXIqiKGPCGIPXN0ivPzjVU0nJkfZ+fvncIcba424wFOajv9nCPU8f4G+745dWTw+ZrpCeh7XgiEMjcH7cmLuAx0Tkw0AJcGVmpqYoyolOKGz4/vp93PfiETr7AgTDhpJ8N/+443JmFMcvoz21GGP4t99uYcOhTs5dVMWy2eWRY609fu55+hU+edUy8j2xz/CBYJiP3L+Zv+44zr+/7lTeccF4l0kfnukYkF4D/MwYU4e14tQvRSRhniJym4hsFJGNra2tGZ+koijp5Z0/eYF7nz047td39gW45acv8r31+zirroLbLlnMbZcspi8Q4u97p989Yt3242w41AnAI9uOxRz72T8P8qNnDrLjaHfM/nDY8KH7XuKvO45z57XLufWSxZM2v0yLQxMwP2q7jsS1aN+LtcQhxpjnsJYVrIl/I2PMPcaYVcaYVbW1SftGKYoyRrr7B2nr9Wf8vD2+QZ7Z18bX/rKLPcd7Rn5BHPuae7j2B8/ywoEOvvamM/jxzefyqauX8emrl1FVks9TeyYuDv/791fYedQ74fcB8A2G+Oq6XSybXcZ5i6p4ZPuxiGspHDb8/iXrtuj1xbrE9rb08PjOZj7+mpN5z6sWpWUuqci0OGwAlorIInsx9JuAtXFjjgBXAIjIqVjiMP1kX1GyjHDY8I6fvMAHf/1Sxs99pKMfgMGQ4VMPbSUYCo/p9T98cj89vkF++4ELWXNefWS/2yVcenItf9/bSig8/rVr9jb38J9/2c0DG46M+z2i+fEzB2jqGuDONyznurPmcqC1jz3Nlig+d6Cdo90+ALwDgzGv6+gLALBqYWVa5jEcGRUHY0wQuB14FNiFlZW0Q0S+KCLX2cP+DbhVRLYC9wO3GF2RSFEmnT9tO8r2pu7IDWiy2HCoA99gKGZfgy0O7790MVsbu7n3H2NzL20+0sVFJ9Vw1vwZCccuO6WWjr4A2xq7xj1nx+1zuL0/4VhDR/+YvrNmr4//fuoVrjptFquX1HD16bNxydA5fvdSI3luAcDrixUH74BlSVQU5Y3rc4yFjLfsNsasA9bF7bsz6vedwEWZnpeiTCXbG7t5fFcz779kMSUF6ftv+eDGBs5fVMWC6pJhx/mDIb756J7I75PFk3taePdPN/ClG07nnVGBVMdy+OBlJ3GgtY9vP7aXwjw3h9v72XO8h/IiD1eeOovLl81MCCy39/o50tHP28+vJxmXLK3FJfDknlZW1g89cbf2+KktKxjVvB/Z7ohDX8Kx9/xsAx63iz/dfhEe9/DP2+t3NfOFP+0kGDJ89nWnAlBTWsAFi6t5ZPsxPnDpEv768nFef8Yc/rDlKN0D8eJgbWdCHKZjQFpRshbfYIiBQOzNt8c3yAd+tYnvr9/HtT94lpebulO8emz0+Ab51EPb+Nk/D4049pfPHaaxc4BFNSX4B8fm0hktgWCYL/15JwB74+IKRzr6mVGcR0VRHl+54XQKPC7u/OMOfv3CYby+QTYc6uTjD27lnC8/wXce3xvz2q22RbAiidUAUFmSz8r6Sp6MSvl8cEMD537liVHFEPY297C/pZea0gIaOwdiXF7+YIhXWnvZdcw77Pfc1DXA+36+gff+fCP5Hhe/eO95MYL9ujPmcKC1j++t30d/IMTbL1hAnlsiloJDt4qDooyPXz53iE8/tG2qpxFDnz/Iwy818oFfbuLsLz3O5d9+ikNtQ0+gX123m2PdA/zHtcsZCIR443//g//7+ysJIjJWHBdI9LmS0T0wyA+f3M/FS2u4ZGkN/uDkiMMvnjvEgdY+ygo87G/pjTl2pGOA+qpiAGaWF/KXf72EJz5+KTu+cDVrb38VL3zmCn7/wdVcuLianzxzgEDUHLcc6cLtEs6oq0h57lefUsv2pm5aenwc6x6IiNSLB9tHnPeftx3DJfDuixYSDBuOdvkixw639xM21s36O4/vTVqQdqitj7f8zz/55yvtfOaaZaz7yMVcsLg6ZozjWvrRMweorypm1YJKKoryEtxK3QODuARK8iff6aPioGQVD21q5HcvNcbcPKaaD9+/mY8/uJXNDZ1cv2IuvsEQa370PIfa+nh6byv3v3iEWy9ezHtftYi/fPRiLjtlJl/7y24u+Np6vvznnUldGaPhkP26g8OIQzhs+Oaju+keGOSOa5ZRkOcet1upoaOfD/56U8INDaCt18/3ntjHZafUctXps3mlNU4c2vuYb4sDwLwZRZw0sxS3y/K9u1zCyvpKbl69kL5AiI2HOiJjNzd0cfKsMoqHuWG+etlMAJ7a08rnfv8yg+EwFUV5bGsc3kozxvDItqOcv6iaVQssl9ShqOvxii1yX3/zmYSN4a61O2Jef6itjzU/eh7fYIjf/b/VvP/SJQl1CzDkWjIG3nT2PESE8sK8BLdS98Ag5UV5uOzvZTJRcVCmNR//zRa+v37fqCpI/cEQO495CYYNB9p6RxyfCboHBvn73lbec9EinrvjCr72pjO579YLIgLx6d9tY0ltCR97zcmA5QK5553n8JvbLuBVS2v42T8P8frvPzuuILFjMTR0DiQVy9YeP+/+2QZ+9fwR3nXBAk6bW0GBx4U/GB5zxS7AE7uaWbf9OI/taE449u3H9jAwGOJzr1/OktpSWnr8EREJhQ2NnQMsiBKHVKxeUk2+28WTeywXUThs2NrQxYr5qa0GgOVzyplZVsC3H9vD+t0tfPKqZZy7sCrikkrFnuYeXmnt4/Vnzom4gQ53DAWlHZG75OQaPnrFyTy2s5n//fsrPLbjOH99+VhEGO679QJOnVOe9BwObzq7jnyPizefXQdAWVFeQraS1zeYEZcSqDgo05i2Xj8Pb27iO4/v5Qt/2jniDWvnUS+DIWvM7mNjz5WfDJ62Uyhff+bsyNPeqXPKIwLR7PXx7beuoDDPHXmNiHD+4mru/pezufvtZ9PrD3JwHGJ3yHYrhcImEvB1+OcrbVzzvWd4/kA7X77hdO667jQACjwujCHyPY6Fvc3WHNfvihWHA629PLChgZtXL+SkmaWcNLMUGHrqPtY9QDBsIm6l4Sgp8HDeoqpI3cLB9j68vmDKeIODiPDqU2bS7PVzdv0Mblm9kLPqKniltS+ppePwiO1Suvr02cwsK6Awz8XhKEvsldY+5s0oojjfw/suXsTyOeX85192c9svN/GBX700amEAePPZ83jxs1dELCjLrZQYc8iUOGQ8W0lRRsuWI9ZT3cX2E7Q/GOIrN5yR0qTe2mCNdwnsOu7lBualfU4HWnu57Zeb+MRrT+Hq02ePOP7J3S1UFuexYn5sXvqpc8r5w4cuoqlrYNgbm3PDPN499sK0w+19lBZ4bHHpi9yUAT75222UFXr49fvO55TZZZH9BR5LpPzBUFL3x3DstfP0n97bij8YirzX715qRID329W8S2qtJ/D9Lb2srK+MCNdoxAGs1NQvP7KLxs7+yDWP/36Tcf3KuTy1t4VvvOVM3C7hTPt7f7mxm9UnJdTZEg4b/rztGBcuqaam1MpqWlBVEhFdsCyHxfbnyXO7ePiDqznU3kcwZAiGDQuqiqksGV3bDhGJycQqL/REUnwdMikOajko05bNDZ14XMI971zFh169hPtfbODrf92dcvzWxm5mlRdw8qyycVXZjkSL18e77n2R/S29/HZjw4jjQ2HDk3tauOyUmRHfeTQLqktYvSTxphTN7PJCwHq6HisH2/q56KRq+/chy6O1x09T1wBvP78+RhgACvKsW8JYg9LGGPYe76G+qpi+QIjnD1gxgXDY8IfNR7l4aS0z7c9SX1VMnlt4pdV2e9k3wPmjFoeh+MGWhi5K8t0xwpeK1UtqeOGzV3LSTOsznznPckVtTRJ3MMZw59qXOdjWx1vOqYvsX1BdzJGOvsiYV1p6WVI7dO7CPDfLZpdz+rwKVsyfMWphSEZFErdS98Ag5YUqDkqOs6Whi2VzyijKd/PJq5bxtlXzufcfB1MGaLc0dHFW3QxOnVOedreS1zfIzT/dQEdfgAsXV/PcgfYRg95bGrro7B+MBEPHw4ziPPI9Lpq9vpEHR9HrD9LW6+fMuhlUl+THBKWdVNnT5yX66Qs84xOHY90+evxB3nXhAory3BHX0ouHOmjqGuBNZw9ZcR63i4XVJRF//eH2fjwuYU5F4ajOtaS2hLrKoog4nFk3I6n4jkRlST4LqosTiuOMMXz5kV386vkjvP/SxdywYmjuC6qLrQylsKHZ66cvEIpYQummvMgKSEe7U712QDoTqDgoU4LXN8gbfvBsxC0QTzhs2NbQHeNy+bfXnozH5eJbj+1NGN/VH+BgWx9nzZ/BstllHPf66OpPT6VvOGx4/y82sa+5h/99xzm8+6KF9AdCbDrcOezrntzdYrVvWDr+3l8iwuzyQo57x+ZWcoLRi2pKWFRTwoHWRHE4bW6iHzziVoqrYB4MhRMyZ6JxWj+cWTeDVy2t4YmdzRhjePilRkry3bx2eawL7qSZpZGYw5GOfuoqi0YsIHNw4gf/fKWNXce8SauiR8uZdTMSMpa+/dhefvLsQW5ZvZA7rl6GyJDwLKguwR8M09zji4hbtOWQTsoL8wiGDQP2tTDGqFtJmV5846+7eedPXhh1v5uOvgC/fP4w4WF62exv6WV7Uzc/T1E49EprLz3+YIwveWZ5Ie+7eBF/2nqU7XH/oR3XwMr5M1hmB/92p8m11NDZz3MH2vnEVadwycm1XLikGo9LeHrf8C2/1u9u4ZwFlVQUT+w/8+zyQpq7x2Y5ODUOC6qLWVRTEmM5bG/qZnFNCWVJ3BOpLIcfPXOAq//r6ZRJAU5R28mzSrny1Jkc7faxuaGLv2w/zjVnzKEo3x0zfkltKYc7+gkEwzR09I/apeRw2Sm19AdCDIbMiMHo4TirroKmrgFaeyzx/cf+Nn745H5uOnc+n3/D8hhhAFjoZCy19w+JwyhcWuPBEQGnEM43GGYwZFQclOmBbzDEL587zDP72rj7yVdG9Zov/Xkn//GHl/nnK6kLjJz/jH/dcZz+QOJiLJuPJK96ve2SxVQW5yXEHrY2dCECZ9RVcKrtR999LD0dNNvtNFLHP19WmMfZ9ZU8PUwb6GPdA+w65uXyCbiUHGZXFHJ8jG4lJxd/YXUJi2pLaOnxRxa9ebmpO6lLCVLHHI52DXCs25eQPeOwp7mHWeUFzCjO5/JlsxCBz/3+ZXr8Qd60MjEx4KSZpYTChsPtfRzp6B91MNrhQjulFWBl/cQsB4BtjV0YY/jmo3uYU1HIXdedliAMYIktWMH+V1p6KS3wMHOULTjGSnmRlS/kWGyZrI4GFQdlBJ7a00KPP8gps8r4/t/2sSWFG8hhe2M3v99stRteuzW+G/sQjjj0B0JJ8+I3N3RRXuhhcU2sP7esMI8PX76UZ/e38UzUk/uWhi5Oqi2lrDCP2rICKovz0mY5dNriUBWVSXLJyTXsOOqNfI54ntxtze2KNIrDWGoPDrX1UVtWQEnB0Hd4qK2P9l4/R7t9nJFKHFK4lXx2S41UgfG9zT2cPMsSz9qyAs6qm8HOY17mVhQmVAPDkCtmsx2XGas4FOd7uHBJNfNmFDGrfHSximScPq8cl1iW5992t7CloYuPXLE0JrU4mjkVheS5hcPt/Rxo62NJbUlSEUkHTuDZSbV1xMERjclGxSFLCYUNP/zbPlp6xvbEGc8ftxylprSAB267gFllBXzsN1uSPumDE8jbSVVJPq9dPou/vHw8ZbVta48fEZhbURgRk2i2NHRx1vwZSdNW335BPfOrivjcH16mu98K2G21x4Plk142uzxt4uAUoFWVRIuDFUd4dn+i9RAKG9ZubaKusmhUWTQjMau8kEAwTFd/ap9/PIfb+1loP+Uutm/Er7RarjxIHoyG1G4lp4vqsa7Ev6dQ2LCvuZdTZg1lPl15qiWK16+cl/QaOumfTr+jsYoDwH+++Qx+9u5zx/y6aIrzPZw8q4ytDV1867G9LKgujslOisfjdjG/0gpKx2cqpZsht5JaDkoaebmpm289tpcHN4yccpmKHt8g63e3cO2Zc6gsyedbbz2Lg219fPi+zdz/4hGe3ddGS5S744ldLbxwsIOPXbmUfzm/nh5fMOUiK629fqpL8nnj2fN4Zl9rzBN4fyDInuNeVqbwJRd43Hz3rSs42jXARx7YzJGOftr7AjEuqGVzrHRWJ+5xrHuAP28b33LkycTh9LkVVJXk88zetpixvsEQH/z1Jp4/0MEtqxem5anSSWcdi2vpYHtfxD9eX1WMiNVGY4fdaO60ecmLsobqHOLFwdo+msRyONLRjz8Y5uSotNjrV8xjxfwZ/Mt5yTullhR4mFtRyDP7rO+vvnrs4jCnooils8pGHjgCZ9ZV8PS+VnYd8/KxK08mb4TAeH11MbuOeTna7Zu0eAMQyUpSt5KSVpwnxJeOjL+H/aM7mgkEw1y3Yi5g5Yl//DUn8/e9rXzm4e284ycvcP7X1vOOH7/AH7c08bW/7GJxbQk3nVfPRSfVUFWSz9qtyW/IrT1+akoLuGHFPMIG/hQ1bltjN2EDK4bxJa9aWMUXrz+dv+9t5UP3WYvTRIvDqbPLGRgMcaSjn1DY8MFfv8SH7988rr5BHf0B8j0uiqOCqi6X8KqTanh6X1tEgLy+QW6+90Ue3dHMndcu530Xp2cJx9kVlk97tOLQ5w/S2uNnoe1OKsxzM29GEQfb+tje2M3C6uKUufKFkZhD7PfkbCezHJzit2jLYX5VMX/40EXDBpqXzCyNxEHGGpBOJ2fWzcAYK5j+hrPmjjh+YXUJB+wA/2SlsUKi5ZDJdt2gFdJZi5OuuPlIJ8aYmCdYYwwvHeniT1uP8vjOZt7zqkW8N8mSg3/c0sT8qqKYJ/iPXLGUD162hONeHw0dA7xwsJ2HNjXy0Qe2APCjd62KPHm97ozZPLSpkT5/MGGNAqeX/tJZZZw+r5w/bGmKLHvoxDXOqhs+0LjmvHp2HO3mV88focDjiinoWjbHDkof7+Hve1sjAW5/MBx5Oh4tnX0BqorzE6yAi5fWsHbrUR7Zfoy9zT08/FITLT0+vnfTCq5fkb7qbMenHp+xdLi9j/mVxQluGycYvSDqadzJWGrvDQwbwB2KOSR3KyWzHJxMpbG60JbUlvLMvjYqi/MyVtiVjAsWV5PnFj599bJR1UtEf6+LJ9GtVFZo/Z9xkgAiMYcMfVcqDlnK9qZuRKCzf5BD7f0ssp8iw2HDjf/3HJsOd5LvcSHAhoMdCeLQ2uPnH/vb+OBlJyXcFD1uF3WVxdRVFnPhkmo+cvlSnj/QTmPnQMTXDJZr4VfPH+Hxnc3cEJex0trjj/idb1gxjy8/soun97ayekk1W450saC6mOrSkbNA7rz2NA629VHgcce4A5bOLEME/ra7mUe2HSPf7SIQCls3vTHGLzv6AjEuJQcn7vDh+zfjEiuD5ls3nsWFSxIDsBNhZlmiW2l7Yzdv+OGzvGb5LL77thWURomvk8a6MGq9gMU1Jdy/oYFAMMy7LhxaZCeeVNlKTq798SQptXuae5hfVTTmRYocl8x44g3p5KSZpWy/66qUQeh4HHFwSaxQpJs8t2WtxruVMlUEp+KQhfiDIfY293DFspk8sauFlw53RsRhW1M3mw538qFXL+EDly7htl9sSrqg/LrtxwgbIi6l4XC5JGlvmnPqK5lbUcjarUdjxMEYQ2vv0Cpc162Yy/fW7+Nd975ISb6bYNiMqm8RQL7HxS/fc37C/qJ8N4uqS3hwYyNFeW4+cOlivv+3/QTGuDYxpBaHWeWF3HntclwCrztzTuQmnm7yPS5qSvNjqqQ3HbbaU6zf1cyb/vsf/Phd50b89pE01qhMr0U1JZGK7lSZShAdkE6VrZTcrXTKOHz/J9lP3VPpUnIYrTAAke6s9VXFY7ZCx0p0C43ugUHKCjzjqrKvg9QAACAASURBVAYfDxpzyEL2HO9hMGS4YeU8ygo8vHRkqJJ3/a5m3C7h1osXU1aYR01ZQVJxeGJXMyfPKo2kJ44Hl0t4w1lzeXpvayQdFCwzORAMU2tbBjPLCln/b5fy/TUredPZdSybUx7TsmA050mWEeO4lj5x1SmRp9T4FM3R0Nk/mLJHzntetYhbLlo0acLgMKu8MOapfecxL9Ul+fziPefT7PVz3d3P8uJBSzAOtfVRU1oQY00sinJ/nDasOKQKSNtupa6BmJTaQDDMgda+cf2dLJk5dJM9kairLMIlk1cZHU154dCCP5lsnQFTIA4icrWI7BGR/SJyR5Lj3xWRLfbPXhEZf0Q1R3GC0WfVzWBF/YyYoPTjO5s5Z0FlpPtjTWk+bb2JbSaaOgdYOnPimSCXnlJLMGwiWTIwVOMQvX7vzLJCrjtrLl+64XT++KGLJtSPyOFNK+u48Zw6blm9cNw9g8C2HCZY5TxR4lto7DzmZfnccl61tIY/fugiqkryeedPXuCxHcc5FJXG6uDUOtRXFQ8b0HQ6sSbGHKxtfzBMZ1RK7cG2PoJhk9DAbzTMLCvkK288nTUpMpqmKwUeN9eeOZerRmndToTyIk+MWylTwWjIsDiIiBu4G7gGWA6sEZHl0WOMMR8zxqwwxqwAfgA8nMk5nggYYyJZHsnY3thNRVEedZVFrKyvZM9xL33+II2d/ew+3hMTF6gpLaDXH4w8GTq0jGHx9eGItBvoGGrfkEwcJoMrl8/imzeehdslKZ+IR8LpKVRVMrlzHYlZFYURt9JgKMze470st3sjLawp4aEPrGbZnHI+8KtNbG3oilmfGGDujCLyPa5hXUoAbpeQ55bEbKXBEHPtxnjRS2E6PZXGa2G+/fwF08KtNFa+v2Ylb101f9LPY7mVrP/rXt9gxgrgIPOWw3nAfmPMAWNMAHgAuH6Y8WuA+zMysxOAcNjw+M5m3vQ//2TFFx7jqT0tScdtb+rmjHkViAgr62cQNtYi7Ot3WeOvPHVWZKzj2omvM+j1B5lZPvEb4uzyQvI9Lo5E9cBvtd1Yk9V2IBlDT8Rjcys5hWdVJVNvOXT0BfAHQ+xv6SUQCrM8agGZqpJ87r/1fF61tBZ/MMyimtgbrtslfP3NZ/DBVy8Z8VwFHneiWykYisQwYtxbR73kuSWSXKCkl+ilQrPacgDmAdFVWY32vgREZAGwCPhbBuY17Tnc3sc133uGW3+xkdYeP/VVxXzk/s0J7audYLRTAXu23bhu85EuntjVzOKakpj0u5oyy70UHXdo8To374n70V0uYX5lUSSDBqIsh9LJ9dNHM163Uqfd2XUiffnTgVMI1+L1DxWyzY21AorzPfz4Xav4/BuW85ZzEp9q37iyLuE1ybCWCh0S0WDIavjmJDVEt9DYcbSbpTPLJj0wm6uUF+XFtM/IZnEYCzcBDxljkj7qichtIrJRRDa2tg7fHTMbuO/FIxxo6+W/3raCpz5xGT9793mICO//5aaYdhZOMPrMOusmUFGcx5LaEp7e28rzB9q54tRYX76zwlV03KGlJ71P9guqS2LW3W3t8ZPvdmXURB6vW6m9N7E6eiqYVTGUzrrzqJfCPFfkZh1NvsfFuy9axOxRro2QjAKPKybm4LO/s7rKYjwu4ahtORhj2HnUy+kpqq2ViVNelEevP0g4nNl23ZB5cWgCoh9p6ux9ybiJYVxKxph7jDGrjDGramvH3y//RGHToU5On1fBDSvn4XG7qK8u5gdrVrK3uYdPPrQtkkHiBKOjfctn11fywsEOBkMmxqUE0eIQZTnY/ZjS4VYCKwh6pL0vMkenAG6yGpYloyBF5e9IOJbDVItDpIVGt48dR7tZNrt80lIaC/Ji3UpOPKqkwM2s8kKO2TGH414f7X2BUVkjyvgoL/RgDLT1+fENhjNaLJhpcdgALBWRRSKSjyUAa+MHicgyoBJ4LsPzm5b4gyG2NXVz7sKqmP2XnFzLJ69axiPbjvHFP+/EGMPLTUPBaIeV9ZZrqaIoj3MWxK61W11qu5V6JsetBFahUF8gFOlR1NrrpyaD8QaIcisNjs1y6EjSkXUqiBaHnce8SRfqSRfxbiVHHAo9bubOKIxYDjuaHPeWWg6ThWMpNHZagjzRtUHGQkaL4IwxQRG5HXgUcAP3GmN2iMgXgY3GGEcobgIeMGPpUZzFvNzUTSAYTrixA3zg0sW09vi59x8HgdhgtMPZC6x2Ca8+pTZhta0Cj5vyQk+c5eAnzy1UpukP0cljP9zRT3VpAa09fubNKBrhVellvG4lRxxmTLE4lBd5KMxzselwJz2+YCRTaTKwxCHacrB+L8hzMaeiKNLeZMdRLyJw6hwVh8nCqWtw1tnOpFsp4xXSxph1wLq4fXfGbd+VyTlNdzYcsorYkomDiPAf154KEBGID1wam5Fy8swy3nnBAt52bvLUO6sQLjrm4KO2NH1uH6fFwJH2fs6ur6S1xz+h1bvGg2M5BMboVuroC1BW6IlkO00VznKhzhoWk+nKKfC4Y2MOjuWQ52ZORSF/fdlHOGzYcbSbRTUlY26boYwex43kWA6ZLILTq3oCsPGQ1f6iJkWvoXiBWBUnIi6X8KUbTk/5/jWlBZH0UrBjAhNYQCWeukqrZfThdqtDakdfemooxkKqnkEj0dmfvHXGVDCrvJBD7f24hHG1qxgtBXku+qLqaBwXkyMOgVCY9r4AO456OTvJA4uSPhxLwUkFz+aAtDJGrA6qnUmthmgcgXj0Xy9JyEgaidrSgoRU1nTWIBTmuZldXsjhjj7a+/yEzeQXwMXjLCk5HrdS5RS7lBycDKQltaUJazKnk1RupUKPizm2O3DXMS9NXQMab5hknIy+hk5LHLI5IK2MkQNtfXT0BTh34chPaCLCKbPLxuwOqinNjw1I9/jSXqBmZSz1R9U4ZFYcPG4XHldi5e9IpGq6NxU4QenJjDdAYhHcQMD6zory3cytsMRh/S5radfTNVNpUnEsBUcc1HJQImyKxBuqRhg5fmpKC/D6gviDIfzBEJ39gxNalzcZC6qLOdzRn7HWGcmIz9+P51j3ADfc/Y+YIq/OaSQOzjVZPskB4IRspWi30gxrDk/Y1fZqOUwuJfkeXAJH7UWWVByUCBsPd1BpF7JNFk5aaXtvIHLzngzLobXHzxE76yKTrTMc8uPcJfFsbehiS0MXz+4bWvqzYxrFHObaLp3JrisoyIsrgou4ldxUFeeT73bR1DXA3IrCKa8cz3ZcLqGsMI9Q2FCU585oYoSKwzRn4yEr3jCZBWPRhXCR6ug0FcA51NuN4DYd7ow5Zyax3CWp3UqtdsaW056iPxDENxieNjGHy5fN5JtvOZPVaV5MKJ54t9JQtpILl0sisY/hWn8r6cOxFjJpNYCKw7SmvdfPgbY+Vi2cPJcSWDEHsMUhzQVwDgvsWodNhzspK/BMakA1FQV5w1sO7XZQfqctDk6NQ/U0eTrO97i4cdX8pGtXpJNURXAF9oI4cxxxUJdSRnCC0plsNwOayjqtcZ6y41NT003EcugJRG4K6Xb7OLUOjZ0DkbUFMs1IMQcnY2vnMS/hsKGzz2p4lmuuEydbyVl73BHUQjsdOFPuLcXCyVBSy0GJ8PJRLy4h0mF1snCCw622W8kljGr95rEwozifcnvB9Ey3znAYya3U1mNZCr3+IA2d/XRE+ipNbbvuTFOQ58YYGAxZDQp8gyFEhtKBHctBG+5lhqlyK6nlMI1p8fqoLi0Y0/q246Ewz01pgdVCo98forq0YFKaui2oLmF7U/eUZCqB9UQ83BrS7X1+Koqs/vk7jnojQjJdYg6ZInod6XyPi4FAiEKPOxL3unHVfKpK8iOptcrk4lgOmayOBrUcpjUtPX5mpTkwnApnudDJqHFwqLddS5mucXCIz8KJp603wPmLqvC4hB1Hu+mw3UrVU7wKXKaJX/vCFwzFxIgW1ZTwvosXZ7Srbi7jNNvLZAEcqDhMa5q9vklfuN6hprSAth7LrTRp4mAHpafOckhc4Syatl4/c2cUcdLMUnYc9dLZF8DtEsoKc8vAjm9S6BsMUzjFvaVyGccdqzEHJcJk3qjjqbFbaFjnnBxBWjDl4uBKGXPwDYbo8QWpKc1n+dxydh710t4XoLI4b9Kzg6YbkT5UdpaSbzA06a5NJTXlmsqqRBMMhWnvzaA4lOXT7PVZ55wkV9ZJM63lSTPdrtshvmdQNO1O2mppAafNraClx8++5p6cizdAErfSYDiSxqpkHq1zUGJo7wsQNjAzQ0E/p4VG2Exe9fI5Cyq5733nT3oRVyriW1FH49Q41JQWRPL3Nzd0TZvq6EwS71byB0ORNFYl80xVKmtuOVOnKQMBq6dR9IIyQ8VomXMrOdROkltJRFh9Us2kvPdoyB/GrdQWEYd8FtdaFk4obHJUHJK4lTxqOUwVp80rZ9WCSs6oy2xdiT4OTAO+um4Xa370Qsy+oXWcM2c5OEyWW2mqGc6t5NQ41JQWUFGUx/wqy/WVawVwkLj2xcCgWg5TycyyQh76f6vT3gxzJPSKTwP2tfSwt7mHYFQOfrNtOWQqlbW2bOgmmOk/wkwxXPuMtr4htxLAaXOsp7Tp0jojkyTNVtKYQ86h4jANaPb6CYUNx+yF28GyHEQy16Auxq00RXUIk02Bx00obGJE2KGtJ0BJvjuSz++smZDbAekht1KRikPOkXFxEJGrRWSPiOwXkTtSjHmriOwUkR0icl+m55hJjDGR9QMO20sBgpXGWlWcT547M5fIEYfK4rwpXy95soisI51EHNr7/DEtQ5ygdG7GHGzLYVCzlXKZjAakRcQN3A28BmgENojIWmPMzqgxS4HPABcZYzpFZGxrXp5geAeCkX75zloHYAWkM1kPUFLgoSjPnbGiu6lgKNAaJt4gaOv1R7rTAlywuJo3n103ZZlVU0l8zMGvMYecJNNX/DxgvzHmgDEmADwAXB835lbgbmNMJ4AxpiXDc8wox71DrqQYcejxZdz3X1OWn7XBaBhqOZ0s7tDWE4hxrZUUePj2W8/KWELAdCLBrRTUIrhcJNPiMA9oiNputPdFczJwsoj8Q0SeF5GrMza7KSBWHPoiv7d4M1cA53D7q0/i5gsXZvScmST+phdNvFspl4kOSAdDYQZDRlNZc5DpWOfgAZYClwF1wNMicoYxpit6kIjcBtwGUF9fn+k5po1mOwi9uLYkYjmEw4bWSaxUTsXbzj1xv8fREJ+F4xAKGzr6AtSW5l58IRn5Ue43X9xaDkrukOkr3gTMj9qus/dF0wisNcYMGmMOAnuxxCIGY8w9xphVxphVtbW1kzbhycaxHM5dUMUROyDd3hcgFDZZ7f+fCqJjDtF02NXoajlYuF1CnlvwB0NRS4Sq5ZBrZFocNgBLRWSRiOQDNwFr48b8ActqQERqsNxMBzI5yUxy3OujqiSfpbNK8fqCdPcPRgrgMlXjkCsMBVpj3UrtcTUOylAH2+j1o5XcIqNX3BgTBG4HHgV2AQ8aY3aIyBdF5Dp72KNAu4jsBJ4EPmmMac/kPDNJc7cVeJ5vdyw93NFHS491s5qsNha5irOSWbxbaag6Wt1KDk4HWyeTTi2H3CPjMQdjzDpgXdy+O6N+N8DH7Z+s57jXx5yKwshaB0c6+unzB4HM9VXKFYaylWItB6evkrqVhnDW21a3Uu6ituIUczzOcjjS0R9pujdV6x5kK6liDo44ZGtl+HgoyLPcSo6QqjjkHtMxWyln8AdDtPcFmF1eSGmBh5rSfI6095PndjGjOE//Q6aZVBXSbb0B8txCeZH+d3BIcCtladW8khr93zCFOBbC7ArriXV+VTFHOvopK/SoS2kSiLiV4iyH9l4/1SUFuiZyFE4H24GAWg65ij4OTCHNXicryQo819vi0OydvKU6c5lURXBtvX5qyjQYHY2zMJJP3Uo5i4rDFOLUOMyuGBKHo10DHO0aUMthEohf/tKhrTegaaxxWO3No7OV9FaRa+gVn0KO29XRs6Msh7CxOrLmYk+fySZVhbTjVlKGcNxKTraStuzOPVQcppBmr48CjyuyNqyTzgqaxjoZ5LkFkaHlL8Fqmd7WG1C3UhzxRXDasjv3UHGYQo57/cyuKIwEQuuro8RBq6PTjogkLBXq9QUJhMLUqOUQg5Ot5NfeSjmLXvEp5Hj3QMSlBDCrrDDS9Cxbl+qcapwnYod2u8ZBLYdYCvKGiuBEhqrLldxBr/gksOuYl86+wIjjjnt9kWA0gMslzK+0FrZXt9Lk4DwRO7T1Oq0z9PuOxhHRgUCIQo9b03xzEBWHSeDtP36B7/9t37BjjDE0e/0xlgMMxR00lXVyyLfbQjg4lkMuLgc6HJEiuKCuAper6FVPM4OhMB19AQ619Q07rrN/kEAwnOA+WjannNnlhZGF7pX0UuBx4Y+qkO4aGASgMn7d0BxnKFsprDUOOYpWSKeZHp/VNK+pa2DYcZE01opYcfjI5Ut59+qFkzI3Zai4y6HbFgcnY0yxKMhzYwz0+AZVHHIUFYc049xsGjsHMMak9NXGV0c7FOW71WqYRJziLgfvwCAel1Cs33kMTsFg94CKQ66ibqU044hDfyBEV/9gynHx1dFKZohPZe0eGKS8KE8DrnEMiUNQYw45il71NOOIA1jWQyqOd/sQ0aykTBOfyto9MKgupSQ41eTegUEKPWo55CIqDmkmWhyauvpTjmv2+qguKSBP88czirWITZRbyRekXMUhAWdJ1a7+gFoOOYpe9TTjHaXlsL+ll3kz1KWUaQry3ATUchgRx63UFwhpzCFHUXFIM47lUOBxpRSHV1p72Xi4k9eeNjuTU1NIjDl4BwYpL9S8jHgKolxJKg65ScbFQUSuFpE9IrJfRO5IcvwWEWkVkS32z/syPceJ4B0YpMDjYmF1SUpxuP+FI3hcwo2r6jI8OyW+Qloth+QURK38pm6l3CSjj0wi4gbuBl4DNAIbRGStMWZn3NDfGGNuz+Tc0oVzs5lXWZS01sE3GOKhlxq56rTZWgU9BUTXORhj8Ko4JKUgShAKNCCdk2T6keA8YL8x5oAxJgA8AFyf4TlMKo441FUW0dSZGJD+y8vH6Oof5F/Or5+C2Sn5URXS/YEQwbDRgHQSogVB625yk0yLwzygIWq70d4Xz5tFZJuIPCQi85O9kYjcJiIbRWRja2vrZMx1XHh9Vt78vBlFeH1BvL7YWodfP3+ERTUlXLi4eopmmNsUeFwEgmGMMVodPQwxbiW1HHKS6ehM/BOw0BhzJvA48PNkg4wx9xhjVhljVtXW1mZ0gsMxZDlYDfSaouIOe473sPFwJ2vOm4/LpUVXU4HjLvEHwxHhVnFIJDYgPR1vE8pkk+mr3gREWwJ19r4Ixph2Y4zf3vwxcE6G5pYWomMOEJvOet8Lh8l3u3jLOUmNISUDRC8V2t2v4pCK6JiDZivlJhMWBxH5kYj8ZJTDNwBLRWSRiOQDNwFr495vTtTmdcCuic4xk3T32+IwwxIHJ+4QDhse2X6M1yyfpe2hpxDHXeIPhiJupfJCFYd4NFtJSUe20qsZpcgYY4IicjvwKOAG7jXG7BCRLwIbjTFrgY+IyHVAEOgAbknDHDNCOGzo8VsVtzWl+TG1Dlsau2jrDfDa02ZN8Sxzm4g4DIY15jAMWuegTFgcjDEnjXH8OmBd3L47o37/DPCZic5rKujxBTEGygs9iEhMOuv6Xc24XcJlJ8+c4lnmNgV5Q24lr91eXcUhkXyPprLmOmovppH4AGddZXHEcli/q4VVCyqpKNYb0VSSzK1UqhXSCbhdQp7bSppQt1JuMqqrLiI3icgnUxz7pIi8Nb3TOjGJd1PMm2FZDo2d/ew+3sOVp6pLaaoZEocw3oFBygo9uDVzLCmOxVCkbqWcZLSPBHcAvhTH+jhB3UDpJl4c6iqL6OgL8KetxwC44lR1KU01kWylwbBWR4+AI6Qac8hNRisOS4GXUxzbZR/PeSLiUDwkDgC/ev4wi2tKWFxbOmVzUyycFM1AyApIa6ZSahxRUHHITUYrDv1YNQnJmA/4UxzLKeJTIx1xaOoaUKthmpDvdrKVQtp0bwSGLAeNOeQio73qTwD/ISIxdzgRqQX+HXgs3RM7EfEmxByKI8eu0HjDtKAwrkJaxSE1+epWymlGm6bxaeB54BUR+StwDJgDXAV0AZ+anOmdWHTHLVY/s6yAPLdQnO9h1YLKKZ6dAnEV0mo5DIuT9qu9lXKT0RavHQHOAn6I5Ua6xv73B8DZxpiGYV6eMzg3G2exepdLOHVOOa87YzYeXQ50WhCfylpepGmsqXC+qwJ1K+Uko/6fYYxpRbOShiXZk+hvbrtQUyWnEY7l0OML4hsMq+UwDAUeFyKxrTSU3GG0dQ5nicjrUhx7nYicmd5pnZh0DwxSFnezKcp3x1SbKlOL8xTc2mPlUKg4pKbA46bQ445YwkpuMdq71neB81McO9c+nvN4fUG92UxznGylFlscdKGf1BTkuTRTKYcZ7ZU/G/hHimPPASvTM50TGy2qmv64XEK+20WL16rpVHFITWm+R1uL5DCjvfJuoCTFsRJAe1DjxBz0P9N0p8DjorVX3UojcfvlJ/HWc3XtkVxltJbDBuC2FMduAzamZzonLs6yk3qzmf4U5Lk05jAK5lcVc46mYOcso33MvQt4QkRewFq28zhWncO7gBXAlZMyuxOIvkCIUNhoO4YTgAKPm7beAKAL/ShKKkYlDsaYp0XktcDXsGobBAgDLwBX2P/mNPHV0cr0JTp7TK+XoiRnLHUOTwEXikgxUAl0AquxVmpbC1RNwvxOGHRVsRMHJ2+/KE/TjBUlFeOJnp4JrAFuBGZhLeV5fzondSKi4nDi4IiDVkcrSmpG9b9DRM7AEoSbgAVAACtD6d+AHxpjgpM2wxOESEdWFYdpj1MlrUKuKKlJaVOLyGIR+XcReRnYgiUEO7CC0Eux4g4vjVUYRORqEdkjIvtF5I5hxr1ZRIyIrBrL+08VajmcODhV0nqtFCU1w1kO+wGDFWx+P/A7Y0wngIhUjOdkIuIG7gZeAzQCG0RkrTFmZ9y4MuCjnECBbq9aDicMjltJxUFRUjNcNO4wlnVwOnAZsFpEJuqkPQ/Yb4w5YIwJAA8A1ycZ9yXg66RemnTa4R0YRATKCtSPPd1x3EqaxqooqUkpDsaYRVjZSD/DSlf9E9AsIj+yt804zjcPiG7v3WjviyAiZwPzjTGPDPdGInKbiGwUkY2tra3jmEp6cZacdGkH1mnPUEBaxUFRUjFsHp8x5nljzEewbuCvBf4AvBl4yB5yazpjAiLiAr6DFd8YFmPMPcaYVcaYVbW1temawrjR6ugTB405KMrIjHaxn7Ax5gljzHux0lffCDxo//uCiOwa5fmasBYJcqiz9zmUYbmxnhKRQ8AFwNoTISitC8ecOETcSioOipKSMVcAGWMGjTF/NMasAWYC7wT2jfLlG4ClIrJIRPKxUmPXRr13tzGmxhiz0BizEGtp0uuMMdO+d5NaDicOGpBWlJGZUHmoMabfGHOfMea6UY4PArcDjwK7gAeNMTtE5IsiMqr3mK7oWg4nDvkqDooyIhn3gxhj1gHr4vbdmWLsZZmYUzpQy+HEQS0HRRkZbSyTJqyYg95sTgSGYg4aI1KUVKg4pAHfYIhAMKx58ycIRfmWOFQW6xpVipIKfXRKAz0+q4NIuS6peELwhjPnUl6Ux6zywqmeiqJMW9RySAM9Pqt1RplaDicEFcV5XHfW3KmehqJMa1Qc0oBjOZRq6wxFUbIEFYc04IhDmbqVFEXJElQc0oC6lRRFyTZUHNJAj18tB0VRsgsVhzQwlK2kloOiKNmBikMacNxKpWo5KIqSJag4pIEeX5CSfDduXctBUZQsQcUhDfT4BjUYrShKVqHikAZ6fEF1KSmKklWoOKSBHl9QM5UURckqVBzSgLqVFEXJNlQc0kCPXy0HRVGyCxWHNNDjC2pHVkVRsgoVhzSgbiVFUbINFYcJMhgK4xsMU6YdWRVFySIyLg4icrWI7BGR/SJyR5LjHxCR7SKyRUSeFZHlmZ7jWIi061a3kqIoWURGxUFE3MDdwDXAcmBNkpv/fcaYM4wxK4BvAN/J5BzHinZkVRQlG8m05XAesN8Yc8AYEwAeAK6PHmCM8UZtlgAmg/MbM7qWg6Io2Uim72jzgIao7Ubg/PhBIvIh4ONAPnB5sjcSkduA2wDq6+vTPtHR4o1YDioOiqJkD9MyIG2MudsYswT4NPC5FGPuMcasMsasqq2tzewEo+jVdt2KomQhmRaHJmB+1HadvS8VDwA3TOqMJoi6lRRFyUYyLQ4bgKUiskhE8oGbgLXRA0RkadTm64F9GZzfmNGAtKIo2UhGH3eNMUERuR14FHAD9xpjdojIF4GNxpi1wO0iciUwCHQCN2dyjmMlksqqdQ6KomQRGb+jGWPWAevi9t0Z9ftHMz2nidDjD1LgcZHvmZbhG0VRlHGhd7QJoq0zFEXJRlQcJohXm+4pipKFqDhMEF3oR1GUbETFYYKoW0lRlGxExWGC9KrloChKFqLiMEHUraQoSjai4jBBenyDlBaoW0lRlOxCxWEChMKGvkBILQdFUbIOFYcJ0Kt9lRRFyVJUHCaA065bO7IqipJtqDhMAO3IqihKtqLiMAG0I6uiKNmKisME6PWr5aAoSnai4jAB1K2kKEq2ouIwARy3UqmKg6IoWYaKwwTw6vrRiqJkKSoOE6DHFyTPLRToQj+KomQZelebAE5HVhGZ6qkoiqKkFRWHCaBN9xRFyVYyLg4icrWI7BGR/SJyR5LjHxeRnSKyTUTWi8iCTM9xtFiWg4qDoijZR0bFQUTcwN3ANcByYI2ILI8bthlYZYw5E3gI+EYm5zgWenxByrQjq6IoWUimLYfzgP3GmAPGmADwAHB99ABjzJPGupvVUwAAC3hJREFUmH5783mgLsNzHDW9/qCmsSqKkpVkWhzmAQ1R2432vlS8F/hLsgMicpuIbBSRja2trWmc4ujRmIOiKNnKtA1Ii8g7gFXAN5MdN8bcY4xZZYxZVVtbm9nJ2Xh9g1rjoChKVpLpx94mYH7Udp29LwYRuRL4d+BSY4w/Q3MbE+GwodevloOiKNlJpi2HDcBSEVkkIvnATcDa6AEishL4P+A6Y0xLhuc3avoCQYzRvkqKomQnGRUHY0wQuB14FNgFPGiM2SEiXxSR6+xh3wRKgd+KyBYRWZvi7aaUtt4AAJXF+VM8E0VRlPST8cdeY8w6YF3cvjujfr8y03MaDw0dVkLV/KriKZ6JoihK+pm2AenpTkOnioOiKNmLisM4aegYIM8tzC4vnOqpKIqipB0Vh3HS2NnP3BlFuF3adE9RlOxDxWGcNHQOML9SXUqKomQnKg7jpLGjn/lVRVM9DUVRlElBxWEc9PmDtPcFqFPLQVGULEXFYRw0dg4AUFeploOiKNmJisM4aNQ0VkVRshwVh3EQKYBTt5KiKFmKisM4aOgcoCjPTU2pts5QFCU7UXEYBw0d/dRVFiGiNQ6KomQnKg7joKFzQOMNiqJkNSoOY8QYQ6NtOSiKomQrKg5jxDsQpMcf1GC0oihZjYrDGBnqxqqWg6Io2YuKwxhx0li1OlpRlGxGxWGM6DoOiqLkAioOY6ShY4DyQg8VRXlTPRVFUZRJQ8VhjDR09qtLSVGUrCfj4iAiV4vIHhHZLyJ3JDl+iYi8JCJBEXlLpuc3Eo2dAxqMVhQl68moOIiIG7gbuAZYDqwRkeVxw44AtwD3ZXJuo8EYQ2Nnv6axKoqS9XgyfL7zgP3GmAMAIvIAcD2w0xlgjDlkHwtneG4JdPcP8vLRbnYd89LRF6C1x49vMKzBaEVRsp5Mi8M8oCFquxE4fzxvJCK3AbcB1NfXj2syD25o4EfPHEh6rD8QoqlrILLtcQkzivNYNruM1Uuqx3U+RVGUE4VMi0PaMMbcA9wDsGrVKjOe95hRnMfSWaVJj+W5Xbx9dj1nzKtg+ZxyqkrytdGeoig5Q6bFoQmYH7VdZ++bEl572mxee9rsqTq9oijKtCXT2UobgKUiskhE8oGbgLUZnoOiKIoyAhkVB2NMELgdeBTYBTxojNkhIl8UkesARORcEWkEbgT+T0R2ZHKOiqIoyhTEHIwx64B1cfvujPp9A5a7SVEURZkitEJaURRFSUDFQVEURUlAxUFRFEVJQMVBURRFSUDFQVEURUlAjBlXcfG0QkRagcPjfHkN0JbG6Zwo5OLnzsXPDLn5uXPxM8PYP/cCY0xtsgNZIQ4TQUQ2GmNWTfU8Mk0ufu5c/MyQm587Fz8zpPdzq1tJURRFSUDFQVEURUlAxcHu7JqD5OLnzsXPDLn5uXPxM0MaP3fOxxwURVGURNRyUBRFURJQcVAURVESyGlxEJGrRWSPiOwXkTumej6TgYjMF5EnRWSniOwQkY/a+6tE5HER2Wf/WznVc003IuIWkc0i8md7e5GIvGBf79/Ya4pkFSIyQ0QeEpHdIrJLRC7MkWv9Mfvv+2URuV9ECrPteovIvSLSIiIvR+1Lem3F4vv2Z98mImeP9Xw5Kw4i4gbuBq4BlgNrRGT51M5qUggC/2aMWQ5cAHzI/px3AOuNMUuB9fZ2tvFRrHVDHL4OfNcYcxLQCbx3SmY1uXwP+KsxZhlwFtbnz+prLSLzgI8Aq4wxpwNurIXEsu16/wy4Om5fqmt7DbDU/rkN+J+xnixnxQE4D9hvjDlgjAkADwDXT/Gc0o4x5pgx5iX79x6sm8U8rM/6c3vYz4EbpmaGk4OI1AGvB35sbwtwOfCQPSQbP3MFcAnwEwBjTMAY00WWX2sbD1AkIh6gGDhGll1vY8zTQEfc7lTX9nrgF8bieWCGiMwZy/lyWRzmAQ1R2432vqxFRBYCK4EXgFnGmGP2oePArCma1mTxX8CngLC9XQ102asRQnZe70VAK/BT2532YxEpIcuvtTGmCfgWcARLFLqBTWT/9YbU13bC97dcFoecQkRKgd8B/2qM8UYfM1Y+c9bkNIvItUCLMWbTVM8lw3iAs4H/McasBPqIcyFl27UGsP3s12OJ41yghET3S9aT7muby+LQBMyP2q6z92UdIpKHJQy/NsY8bO9udsxM+9+WqZrfJHARcJ2IHMJyF16O5YufYbsdIDuvdyPQaIx5wd5+CEsssvlaA1wJHDTGtBpjBoGHsf4Gsv16Q+prO+H7Wy6LwwZgqZ3RkI8VwFo7xXNKO7av/SfALmPMd6IOrQVutn+/Gfhjpuc2WRhjPmOMqTPGLMS6rn8zxrwdeBJ4iz0sqz4zgDHmONAgIqfYu64AdpLF19rmCHCBiBTbf+/O587q622T6tquBd5lZy1dAHRHuZ9GRU5XSIvI67B8027gXmPMV6Z4SmlHRF4FPANsZ8j//lmsuMODQD1Wu/O3GmPig10nPCJyGfAJY8y1IrIYy5KoAjYD7zDG+KdyfulGRFZgBeHzgQPAu7EeArP6WovIF4C3YWXnbQbeh+Vjz5rrLSL3A5dhteVuBj4P/IEk19YWyR9iudf6gXcbYzaO6Xy5LA6KoihKcnLZraQoiqKkQMVBURRFSUDFQVEURUlAxUFRFEVJQMVBURRFSeD/t3dvIVZVcRzHv79QkGCiiwwIPhoF1YR0gZApC+qhqLCLGvVgUNBFsBAyHBCjiILMh0iKIXvoaZoHH6QQu1BpEBKU1EMXEEKZTDgxpOZlyr8P/3V0z96nnBkOTXh+H9ic2Xst1l7nPOz/rLU26+/gYPY/IGmppJB09Wz3xQwcHMzMrAMHBzMza3BwsJ4maVDS55L+lNSSNCypr5StKlM9N0jaJemYpJ8kLevQzuqScOVESbDybIc6A5K2SxqXdETSHkm316rNlzRayvdJeqrWxlWSdkj6XdLRktDn6a7+KGY4OFgPk7QE+Jjc6vgB4BngTuDdWtURcs+a+8htSEYlXVtp53HgDXI/m7uBUWCTKtkFJV0JfAksAJ4AlgHbmLw5GsAwsLeUfwa8KenGSvl24G/gEeCect++mXx/s3/j7TOsZ0naBfwVEbdWrt1GZtS6BrieDBRDEfFyKb+A3NTt24hYWc73Azsj4tFKO1uAh8n99o+XfXEGgcsj4liHviwlN4p7MSI2lGtzgTHgnYh4XtJ8Ml/DQER81+Wfw2wSjxysJ0m6ELgJeF/SnPYB7AYmgOsq1be1/4iIU+Qoov3f/EIyh8Bo7RYjwEVkkIHcNnykU2Co2Vm51wTwc7kHZBaw/cBbklZI6p/KdzWbCQcH61WXkLvxbiGDQfs4Acxl8nRPPf/BIXJ6iMrnb7U67fNLy+dlZJaycxmvnZ8E5sGZwHQHOQ22FThY1kIWT6Fds2mZc+4qZuelcTJr1kbgww7lY+SDGKAfaFXK+jn7oP+1cq2qna6xvTV2i7OBZMYi4gfg/jLlNAi8CnwgaWEJHmZd4ZGD9aSIOAp8BVwREV93OMYq1c+8nVTWGO4F9pRLB8hA8mDtFsuBP8gFbMh1jOWS5nWp/xMR8SnwOhl0Lu5Gu2ZtHjlYL3sO+ETSKTKl5mEyacpdwFCl3mOSTgLfk0lkFgEPQU71SNoIvC2pBXwE3AI8CayPiOOljRfI7INfSNpEjiQWA62I2DqVzkoaAF4j1zP2kVNj64C951vyHpt9Dg7WsyJit6SbyQf3e+QaxC/ADiavIawENgMvkQvCKyLim0o7w2VEsKYcB4C1EbG5UufHkpXvFTJTG+RbT+un0eWDpV9D5CL4OPmG07pptGE2JX6V1ewfSFpFvsraFxFHZrk7Zv8przmYmVmDg4OZmTV4WsnMzBo8cjAzswYHBzMza3BwMDOzBgcHMzNrcHAwM7OG0/rdgcnxJIP3AAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Validation Accuracy', fontsize=15)\n",
        "plt.xlabel('epochs', fontsize=15)\n",
        "plt.ylabel('Acc.', fontsize=15)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLf12NSyzxer"
      },
      "source": [
        "## Test Accuracy\n",
        "\n",
        "test accuracy 측정 결과 **80% 이상**이 나와야 한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TZdoqT9zxer",
        "outputId": "fe890565-fcb8-478b-e793-d79bc9815364",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 8ms/step - loss: 0.7732 - accuracy: 0.7916\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.7732448577880859, 0.7915999889373779]"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my_mobilenet.evaluate(x_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3w4juXElY0h"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
